{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da28d345",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align: center; font-size: 30pt\"> INTRODUCTION TO OBJECT DETECTION </h1>\n",
    "<h1 style=\"text-align: center; font-size: 18pt; margin-bottom:50px; font-family:Arial\"> Abubakar Abdulkadir </h1>\n",
    "<img src='images/person.jpg' width='100%' height='200px'/><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b4a63b",
   "metadata": {},
   "source": [
    "Object detection is a remarkable computer vision Technique which enables the computer to identify specific objects within an image and to also determine their precise location within the image. \n",
    "\n",
    "Before object detection, Convolutional Neural networks provides prominent methods for classifying images into different classes. We can feed a picture into a Convolutional Neural Network and the network is able to identify if the picture is that of a dog, or a cat or a car etc. This task is called <b> Image Classification.</b> <br><br>\n",
    "\n",
    "<img src=\"images/class.png\" />\n",
    "\n",
    "Image Classification serve as a base for object detection. However, while image classification indeed represented a significant achievement, it had its limitations. Beyond merely knowing the overall content of an image, there is the need to know the precise whereabouts of individual objects within the Image or how many objects are there. This requirement became especially evident in practical applications such as self-driving cars or medical diagnostics where deeper level of understanding was essential to ensure safety and optimal decision-making.\n",
    "\n",
    "<b> Object localization </b> is an approaches which arose to solve the problem of identifying precise location of objects in an image. Object localization deals with predicting bounding boxes that tightly enclose each individual object present in an image. The bounding boxes indicate the position and size of the objects, allowing for their precise location within an image to be indentified. \n",
    "\n",
    "In this approach, the algorithm uses regression technique to determine the coordinates of the box's top-left and bottom-right corners, effectively defining a rectangular region around the detected object. <br><br>\n",
    "\n",
    "<img src=\"images/localization.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b4f429",
   "metadata": {},
   "source": [
    "<b> Object Detection </b> is a combination of image classification and object localization. With these two techniques combined, an objected can be detected within a picture (classification) and also its position predicted through the use of bounding boxes (localization).  <br><br>\n",
    "<img src=\"images/detection.png\" />\n",
    "\n",
    "The object detection approach generally consist of two ideas. The first is detecting all the objects in the image and the second involves, predicting the bounding boxes for each of the detected object. \n",
    "\n",
    "- The Classification\n",
    "\n",
    "    The native multiclass and multilabel Image classification algorithms is limited for object detection use case. The <b>Multiclass image classification </b> classifies an image into one of several classes. It takes a picture and predicts cat or a dog or goat etc. It means that the Multiclass classification is most useful for identifying one object at a time. In object detection, we want to detect deveral objects at a time. \n",
    "\n",
    "    The <b> Multilabel classification </b> detects if one of several objects is present in the image. i.e it can predict 1, 1, 0, 0 indicating that there is a dog, a cat, no goat, no cow in the image. This means that it can detect two or more objects of different kinds but will fail when there are multiple objects of the same kinds in the image. When there are three cows in the image, it can only detect that there is a cow and not three cows. In object detection, we want to detect all the objects in the image whether they are same class or not. <br /><br />\n",
    "    \n",
    "- The regression\n",
    "\n",
    "    In object detection, the task of regression is similar to the native regression problem, where the goal is to predict floating-point numbers. However, in object detection, the regression network needs to predict four floating-point numbers per detected object, representing the bounding box coordinates (top-left x and y, bottom-right x and y) for each object.\n",
    "\n",
    "    Despite the majority of regression use cases outputting a single floating-point number, the regression network can still handle multiple floating-point outputs when trained on target values y of shape (n, 4), where n is the number of training examples, and 4 represents the four bounding box coordinates.\n",
    "    \n",
    "Several methodologies have been proposed over the years beuilding on the combination of object detection and classification. Here are some of them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ebb9b9c",
   "metadata": {},
   "source": [
    "## Sliding Windows Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe3c2b3",
   "metadata": {},
   "source": [
    "The major challenge in using pure image classification and regression algorithms for object detection is their inability to detect all objects in an image. The Sliding Windows algorithm addresses this by sliding windows of various sizes and spacings across the image, extracting portions of the image to feed into a trained classification network. The trained classification network can then detect if there is an object of interest in that portion or not. If the portion contains an object, it is kept else it is discarded. In the illustrative images bellow, yellow windows indicate detection of objects and the red ones are windows which are negative. In image (b), the windows which do not detect any object have been discarded. We still have several windows detecting the same object. <br /><br />\n",
    "\n",
    "<div style='display: inline-block; width: 40%'><img src='images/slide.png' width='100%'/></div>\n",
    "<div style='display: inline-block;  width: 40%; margin-left: 150px;'><img src='images/slide2.png' width='100%'/></div>\n",
    "\n",
    "The technique known as <b>Non-maximum Suppression (NMS)</b> is used to select the best-fitting bounding box among all the boxes that detect the same object. NMS helps eliminate duplicate detections by considering the predicted bounding boxes' intersection over union (IoU) with the ground-truth bounding box. \n",
    "\n",
    "<p style='font-size: 14pt; text-align: center'> IoU = $\\frac{Area \\ of \\ Intersection}{Area \\ of \\ Union} = \\frac{BB_{\\text{overlap}}}{BB_{\\text{union}}}$ </p>\n",
    "\n",
    "The predicted box with the highest IoU is kept as the best-fitting box, while other overlapping boxes are suppressed to avoid redundant detections. This ensures that each object is only detected once, leading to more accurate and efficient object detection results. \n",
    "\n",
    "The challenge with the Sliding Windows algorithm lies in its computational efficiency, particularly when dealing with larger images or numerous objects. As the algorithm slides the window across the image and extracts portions of it at each position, it needs to classify each of these extracted regions to identify objects and their bounding boxes. The process of classifying every portion of the image can be computationally expensive, especially if the image is large or if there are many objects to detect. Moreover, the sliding window needs to be moved in small increments to ensure that no objects are missed, leading to redundant computations as overlapping regions may be processed multiple times. \n",
    "\n",
    "As a result of these repetitive computations and the need to process numerous regions, the Sliding Windows algorithm can become slow and inefficient, making it less practical for real-time applications or scenarios with stringent speed requirements."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9564327f",
   "metadata": {},
   "source": [
    "# R-CNN Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8f8e83",
   "metadata": {},
   "source": [
    "The sliding windows algorithm conducts classification and regression for every window in the image, regardless of whether the window contains any relevant features. On the other hand, in the Region Convolutional Neural Network, selective search is applied to the image. This yields around 2000 region proposals which is way smaller than what the number of windows which would have been generated using sliding windows. Consequently, rather than processing all image subsections, attention is focused on these proposed regions and we can run our classification and regression algorithms on these subsections.\n",
    "\n",
    "<img src='images/rcnn.png' width='100%'/>\n",
    "\n",
    "The RCNN Algorithm generally consists of three modules - The feature proposal, the feature extraction and the region classification.\n",
    "\n",
    "- <b> Region Proposals: </b>\n",
    "\n",
    "    The object detection algorithm begins by taking an input picture and generating approximately 2000 region proposals using the bottom-up selective search technique. This approach uses the pixel intensities of the image to perform segmentation, dividing the picture into different segments. These segments are added to the list of region proposals, and the process is repeated iteratively. During each repetition, larger segments are generated, making it a \"bottom-up\" process. This means that it starts with smaller segments and progressively creates larger ones until reaching the desired number of around 2000 region proposals. The result is a diverse set of potential object regions that the algorithm will further evaluate for object detection.\n",
    "    \n",
    "<img src='images/regions.jpg' width='50%'/>\n",
    "\n",
    "- <b> Feature Extraction: </b>\n",
    "The next step in the RCNN is the feature extraction which involves extracting fixed size features vector of 4096-dimension from each region proposal. These features are important in classifying the regions as one of our interest objects. <br><br>\n",
    "\n",
    "- <b>Region Classification:</b>\n",
    "    In RCNN, the process of region classification involves using Support Vector Machines (SVMs) trained to detect each object of interest to classify the generated regions. For instance, if the objects of interest are cars and people in an image, each region is separately passed through the car detector SVM. If the region contains a car, the SVM returns a positive detection; otherwise, it returns a negative detection. Similarly, the region is passed through the Person Detector SVM to determine if it contains a person.\n",
    "    Since the same object might be detected multiple times in different regions, a non-maximum suppression (NMS) technique is employed to discard duplicate detections. This ensures that each object is only detected once, improving the accuracy and efficiency of the object detection process. By using SVMs to classify regions and applying NMS to handle duplicate detections, the RCNN algorithm achieves robust and accurate object detection across various objects of interest within the input image.\n",
    "    \n",
    "The challenge with the R-CNN algorithm is the speed and the memory requirement. The algorithm is quite slow because it employs selective search to extract region proposals and then applies separate CNNs on each region. It is also memory consuming due to the storage of the proposed regions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4d2a6a",
   "metadata": {},
   "source": [
    "# Fast R-CNN Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a2f1b1",
   "metadata": {},
   "source": [
    "Fast R-CNN builds upon the original R-CNN approach by introducing notable improvements.  Instead of employing selective search to make region proposals, Fast R-CNN extracts feature maps from the image using a single CNN. These feature maps are then utilized for region proposals by employing a technique known as Region of Interest (RoI) pooling. RoI pooling aligns the proposed regions to a fixed size, ensuring efficient processing and enhancing the overall object detection process.\n",
    "\n",
    "<img src='images/fast_rcnn.png' width='100%' />\n",
    "\n",
    "Fast R-CNN employs several in novations to improve training and testing speed while also increasing detection accuracy. Fast R-CNN trains the very deep VGG16 network 9× faster than R-CNN, is 213× faster at test-time, and achieves a higher mAP on PASCAL VOC 2012."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0c68ee",
   "metadata": {},
   "source": [
    "# YOLO Algorithm (You Only Look Once)\n",
    "\n",
    "Several variants of object detection algorithms have been developed over the years with varying performances. Although one which stands out and is currently a favourite due to its significant difference in speed is the YOLO algorithm. \n",
    "\n",
    "The difference between this algorithm and earlier variants is that, this algorithm does not involve multiple stages of classification and prediction from several loops on region proposals. It predicts the objects present in the image and their bounding boxes all in one pass over a convolutional neural network. How is this even possible? Dont we need to identify every item at every position in the picture? How then does YOLO pick out all the objects in the picture without several region proposals? \n",
    "\n",
    "Although, YOLO does not make use of region proposals, it uses a concept similar. Instead of region proposals, YOLO conceptually divides the input image into fixed-sized grids. For an instance, YOLO version 1 uses a 7 x 7 grid. Each grid is responsible for making one prediction, something similar to the region proposals. Except that, unlike the region proposals where we need to extract features and classiify them with different networks, YOLO does in one single network pass. \n",
    "\n",
    "The YOLO model reduces object detection problem into a regression problem. The network takes an input image of shape 448 * 448. It passes the image through a convolutional neural network where features of shape 7 x 7 are extracted. Each extracted feature represents a grid. The 7 x 7 features are passed into a dense layer and all the image class predictions and the bounding boxes are predicted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6483128",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
