{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da28d345",
   "metadata": {},
   "source": [
    "<h1> Object Detection With Deep Learning </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b4a63b",
   "metadata": {},
   "source": [
    "Object detection is a remarkable computer vision Technique which empowers the computer to identify specific objects within a picture and also determine their precise location within the scene. Before object detection, Convolutional Neural networks serve as a prominent method for classifying images into different classes. For an example, we can feed a picture into a Convolutional Neural Network and the network is able to identify if the picture is that of a dog, or a cat or a car or all. This task is called <b> Image Classification.</b> <br><br>\n",
    "\n",
    "<img src=\"images/classification.png\" />\n",
    "\n",
    "Image Classification serve as a base for object detection. However, while image classification indeed represented a significant achievement, it had its limitations. Beyond merely knowing the overall content of an image, there is the need to know the precise whereabouts of individual objects within the scene or how many objects are there. This requirement became especially evident in practical applications such as self-driving cars, medical diagnostics where a deeper level of understanding was essential to ensure safety and optimal decision-making.\n",
    "\n",
    "Object localization is an approaches which arose to solve the problem of identifying precise location of objects in an image. Object localization deals with predicting bounding boxes that tightly enclose each individual object present in an image. The bounding boxes indicate the position and size of the objects, allowing for their precise localization. In this approach, the algorithm determines the coordinates of the box's top-left and bottom-right corners, effectively defining a rectangular region around the detected object. <br><br>\n",
    "\n",
    "<img src=\"images/localization.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b4f429",
   "metadata": {},
   "source": [
    "A combination of image classification and object localization results to object detection. With these two techniques combined, an objected can be detected within a picture and also its position predicted through the use of bounding boxes. <br><br>\n",
    "<img src=\"images/object detection.png\" />\n",
    "\n",
    "This solution involves having a object detection network which consists of both a classification and regression output. The network takes a image as input and classifies the image into one of several classes. Then it also regresses the image to figure out the bounding box of the detected object.\n",
    "\n",
    "The challenge of this earlier approach is that, the network cannot detect multiple objects in a single image pass. How do we detect every object in the image? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ebb9b9c",
   "metadata": {},
   "source": [
    "## Sliding Windows Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe3c2b3",
   "metadata": {},
   "source": [
    "The Sliding Windows algorithm was introduced to address the task of detecting multiple objects in an image. It involves sliding a window across the image and extracting portions of the image at each window position. These extracted portions are then fed into a classification and regression network, which helps determine both the object's identity and the bounding box around it within that specific region of the image.\n",
    "\n",
    "The challenge with the Sliding Windows algorithm lies in its computational efficiency, particularly when dealing with larger images or numerous objects. As the algorithm slides the window across the image and extracts portions of it at each position, it needs to classify and regress each of these extracted regions to identify objects and their bounding boxes. The process of classifying and regressing every portion of the image can be computationally expensive, especially if the image is large or if there are many objects to detect. This is because for each window position, the classification and regression network must process the extracted portion, which requires considerable computational resources. Moreover, the sliding window needs to be moved in small increments to ensure that no objects are missed, leading to redundant computations as overlapping regions may be processed multiple times. \n",
    "\n",
    "As a result of these repetitive computations and the need to process numerous regions, the Sliding Windows algorithm can become slow and inefficient, making it less practical for real-time applications or scenarios with stringent speed requirements."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9564327f",
   "metadata": {},
   "source": [
    "# R-CNN Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8f8e83",
   "metadata": {},
   "source": [
    "The sliding windows algorithm conducts classification and regression for every window in the image, regardless of whether the window contains any relevant features. On the other hand, in the Region Convolutional Neural Network, selective search is applied to the image using windows of various sizes. This yields around 2000 region proposals which is way smaller than what the number of windows which would have been generated using sliding windows. Consequently, rather than processing all image subsections, attention is focused on these proposed regions and we can run our classification and regression algorithms on these subsections."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4d2a6a",
   "metadata": {},
   "source": [
    "# Fast R-CNN Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a2f1b1",
   "metadata": {},
   "source": [
    "The challenge with the R-CNN algorithm is the speed and the memory requirement. The algorithm is quite slow because it employs selective search to extract region proposals and then applies separate CNNs on each region. It is also memory consuming due to the storage of the proposed regions. Fast R-CNN builds upon the original R-CNN approach by introducing notable improvements.  Instead of employing selective search, Fast R-CNN processes the entire image using a single CNN to extract feature maps. These feature maps are then utilized for region proposals, employing a technique known as Region of Interest (RoI) pooling. RoI pooling aligns the proposed regions to a fixed size, ensuring efficient processing and enhancing the overall object detection process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0c68ee",
   "metadata": {},
   "source": [
    "# YOLO Algorithm (You Only Look Once)\n",
    "\n",
    "Several variants of object detection algorithms have been developed over the years with varying performances. Although one which stands out and is currently a favourite due to its significant difference in speed is the YOLO algorithm. The difference between this algorithm and earlier variants is that, this algorithm does not involve multiple stages of classification and prediction from several loops of region proposals. It predicts the objects presents in the image and their bounding boxes all in one pass over the network. How is this possible?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3047068d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
